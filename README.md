100 days of Code - Section 45


use url.robots.txt to view what the website is allowing robots to scrape.
User-agent : the person scraping
Crawl-dealy : how often your script should scrape

